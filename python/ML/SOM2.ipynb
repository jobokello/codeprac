{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-4b36dfc6f9d6>, line 71)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4b36dfc6f9d6>\"\u001b[0;36m, line \u001b[0;32m71\u001b[0m\n\u001b[0;31m    for x in range(net.shape[0]):\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "raw_data = np.random.randint(0, 255, (3,100))\n",
    "\n",
    "network_dimensions = np.array([5, 5])\n",
    "n_iterations = 2000\n",
    "init_learning_rate = 0.01\n",
    "\n",
    "m = raw_data.shape[0]\n",
    "n = raw_data.shape[1]\n",
    "\n",
    "net = np.random.radom((network_dimensions[0], network_dimensions[1], m))\n",
    "\n",
    "init_radius = max(network_dimensions[0], network_dimensions[1])/2\n",
    "\n",
    "time_constant = n_iterations/ np.log(init_radius)\n",
    "\n",
    "normalise_data = True\n",
    "\n",
    "normalise_by_column = False\n",
    "\n",
    "data = raw_data\n",
    "\n",
    "if normalise_data:\n",
    "    if normalise_by_column:\n",
    "        col_maxes = raw_data.max(axes=0)\n",
    "        data = raw_data/col_maxes[np.newaxis, :]\n",
    "        \n",
    "t = data[:, np.random.randint(0, n)].reshape(np.array([m, 1]))\n",
    "\n",
    "bmu, bmu_idx = find_bmu(t, net, m)   \n",
    "\n",
    "\n",
    "def find_bmu(t, net, m):\n",
    "    \"\"\"\n",
    "        Find the best matching unit for a given vector, t, in the SOM\n",
    "        Returns: a (bmu, bmu_idx) tuple where bmu is the high-dimensional BMU\n",
    "                 and bmu_idx is the index of this vector in the SOM\n",
    "    \"\"\"\n",
    "    bmu_idx = np.array([0, 0])\n",
    "    # set the initial minimum distance to a huge number\n",
    "    min_dist = np.iinfo(np.int).max\n",
    "    # calculate the high-dimensional distance between each neuron and the input\n",
    "    for x in range(net.shape[0]):\n",
    "        for y in range(net.shape[1]):\n",
    "            w = net[x, y, :].reshape(m, 1)\n",
    "            # don't bother with actual Euclidean distance, to avoid expensive sqrt operation\n",
    "            sq_dist = np.sum((w - t) ** 2)\n",
    "            if sq_dist < min_dist:\n",
    "                min_dist = sq_dist\n",
    "                bmu_idx = np.array([x, y])\n",
    "    # get vector corresponding to bmu_idx\n",
    "    bmu = net[bmu_idx[0], bmu_idx[1], :].reshape(m, 1)\n",
    "    # return the (bmu, bmu_idx) tuple\n",
    "    return (bmu, bmu_idx)\n",
    "\n",
    "r = decay_radius(init_radius, i, time_constant)\n",
    "l = decay_learning_rate(init_learning_rate, i, n_iterations)\n",
    "\n",
    "def decay_radius(initial_radius, i, time_constant):\n",
    "    return initial_radius * np.exp(-i / time_constant)\n",
    "\n",
    "def decay_learning_rate(initial_learning_rate, i, n_iterations):\n",
    "    return initial_learning_rate * np.exp(-i / n_iterations)\n",
    "\n",
    "def calculate_influence(distance, radius):\n",
    "    return np.exp(-distance / (2* (radius**2))\n",
    "\n",
    "# now we know the BMU, update its weight vector to move closer to input\n",
    "# and move its neighbours in 2-D space closer\n",
    "# by a factor proportional to their 2-D distance from the BMU\n",
    "for x in range(net.shape[0]):\n",
    "    for y in range(net.shape[1]):\n",
    "        w = net[x, y, :].reshape(m, 1)\n",
    "        # get the 2-D distance (again, not the actual Euclidean distance)\n",
    "        w_dist = np.sum((np.array([x, y]) - bmu_idx) ** 2)\n",
    "        # if the distance is within the current neighbourhood radius\n",
    "        if w_dist <= r**2:\n",
    "            # calculate the degree of influence (based on the 2-D distance)\n",
    "            influence = calculate_influence(w_dist, r)\n",
    "            # now update the neuron's weight using the formula:\n",
    "            # new w = old w + (learning rate * influence * delta)\n",
    "            # where delta = input vector (t) - old w\n",
    "            new_w = w + (l * influence * (t - w))\n",
    "            # commit the new weight\n",
    "            net[x, y, :] = new_w.reshape(1, 3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
